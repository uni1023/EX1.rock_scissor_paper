{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sorted-black",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/r_s_p/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "favorite-asbestos",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/r_s_p/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intimate-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/r_s_p/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이거는 라벨링작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "visible-attempt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/r_s_p\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lyric-reform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "concerned-leadership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2797 - accuracy: 0.2938\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0738 - accuracy: 0.3727\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9445 - accuracy: 0.6489\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8341 - accuracy: 0.7499\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7165 - accuracy: 0.8506\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.9826\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.9991\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1900 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1072 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 1.0000\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "# 바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10 # 에포크, 실행되는 횟수\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='elu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='elu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='elu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch) # fit() 학습을 시작해! 라고 하는것\n",
    "# x_train_norm(정규화된값을 넣어야함)\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 불러오기 + 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fatal-computer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n",
      "학습데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/r_s_p/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/r_s_p/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/r_s_p/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "# 아래는 라벨링 작업\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/r_s_p/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 값 입력 후 결과 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "usual-tradition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1415 - accuracy: 0.3327\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0068 - accuracy: 0.4832\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8854 - accuracy: 0.6812\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7602 - accuracy: 0.7434\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.8208\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.8723\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.7862\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.8198\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.8277\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8467\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3224 - accuracy: 0.8926\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8935\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.9218\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2331 - accuracy: 0.9537\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2063 - accuracy: 0.9316\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2010 - accuracy: 0.9265\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1418 - accuracy: 0.9515\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1394 - accuracy: 0.9515\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9824\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9683\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0958 - accuracy: 0.9866\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9927\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9896\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0801 - accuracy: 0.9770\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9944\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9802\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9833\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9888\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9960\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9960\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "# 바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_test_epoch=30 # 에포크, 실행되는 횟수\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='elu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='elu')) # relu -> elu 함수로 변경\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='elu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_test_norm, y_test, epochs=n_test_epoch) # fit() 학습을 시작해! 라고 하는것\n",
    "# x_test_norm(정규화된값을 넣어야함)\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-nepal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
